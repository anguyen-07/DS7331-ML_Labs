{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andy Nguyen, Michael Wolfe, Spencer Fogelman, Joseph Caguioa\n",
    "\n",
    "DS 7331-407\n",
    "\n",
    "Thursday 6:30 - 8:00 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center><h1>Lab 3: Cluster Analysis of AirBnb listings in major U.S. cities</h1></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "*Dataset Source: https://www.kaggle.com/rudymizrahi/airbnb-listings-in-major-us-cities-deloitte-ml*\n",
    "\n",
    "This Kaggle dataset contains data on AirBnb listings for 6 major U.S. cities (CHI, DC, LA, NYC, SF, BOS). The competition's original objective was to use the provided attributes to predict the price of a listing. However, the dataset can be adjusted to predict other variables as well.\n",
    "\n",
    "In this notebook, we will use the data on these AirBnb listings to practice clustering algorithms to extract new features from the available data. We will use these new features to build new classifiers and assess any improvements in performance compared to the classification models in our previous notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import warnings\n",
    "\n",
    "#from plotnine import *\n",
    "%matplotlib inline\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def EncodeCategory(col_to_encode):\n",
    "    distinct_cats = col_to_encode.unique()\n",
    "    encode_list = []\n",
    "    i = 1\n",
    "    for cat in distinct_cats:\n",
    "        encode_list.append([cat,i])    \n",
    "        i += 1\n",
    "    return(encode_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('https://raw.githubusercontent.com/anguyen-07/DS7331-ML_Labs/master/data/airbnb_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['price'] = np.exp(df['log_price'])\n",
    "df['grade'] = pd.cut(df.review_scores_rating, [0,60,70,80,90,101], right=False, labels = ['F', 'D', 'C', 'B', 'A'])\n",
    "df[['grade', 'review_scores_rating']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up datatypes and duplicates\n",
    "df_ratings = df.dropna(subset=['review_scores_rating'])\n",
    "df_ratings.drop_duplicates(inplace=True)\n",
    "floats = ['log_price','bathrooms','latitude','longitude','review_scores_rating', 'price']\n",
    "df_ratings[floats] = df_ratings[floats].astype(np.float64)\n",
    "ints = ['id','accommodates','number_of_reviews','bedrooms','beds']\n",
    "df_ratings[\"host_response_rate\"] = df_ratings[\"host_response_rate\"].str.rstrip('%').astype(np.float64)/100\n",
    "date_time = ['first_review','host_since','last_review']\n",
    "df_ratings[date_time] = df_ratings[date_time].apply(pd.to_datetime)\n",
    "booleans = ['host_has_profile_pic','host_identity_verified','instant_bookable']\n",
    "df_ratings[booleans] = df_ratings[booleans].replace({'t':True,'f':False})\n",
    "df_ratings[booleans] = df_ratings[booleans].astype(np.bool)\n",
    "categorical = ['property_type','room_type','bed_type','cancellation_policy','city','neighbourhood','zipcode']\n",
    "df_ratings[categorical] = df_ratings[categorical].astype('category')\n",
    "df_ratings.drop_duplicates()\n",
    "df_ratings.host_since[df_ratings.host_since.isna()] = df_ratings.first_review[df_ratings.host_since.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Impute missing values\n",
    "df_imputed = df_ratings\n",
    "df_imputed[\"bathrooms\"] = df_imputed[\"bathrooms\"].fillna(df_imputed.groupby([\"property_type\",\"accommodates\"])[\"bathrooms\"].apply(lambda x : x.fillna(x.median())))\n",
    "df_imputed[\"bedrooms\"] = df_imputed[\"bedrooms\"].fillna(df_imputed.groupby([\"property_type\",\"accommodates\"])[\"bedrooms\"].apply(lambda x : x.fillna(x.median())))\n",
    "df_imputed[\"beds\"] = df_imputed[\"beds\"].fillna(df_imputed.groupby([\"property_type\",\"accommodates\"])[\"beds\"].apply(lambda x : x.fillna(x.median())))\n",
    "df_imputed[\"host_response_rate\"] = df_imputed[\"host_response_rate\"].fillna(df_imputed.groupby([\"number_of_reviews\"])[\"host_response_rate\"].apply(lambda x : x.fillna(x.mean())))\n",
    "# Impute Missing Value of for 100% Host Response Rate for Row 48194 - Private Room in Apartment\n",
    "df_imputed[\"host_response_rate\"][df_imputed[\"host_response_rate\"].isna()] = 1.0\n",
    "df_imputed[ints] = df_imputed[ints].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#Create a new cleaned amenities column where all amenities are in list form\n",
    "df_imputed['amenities_new'] = df_imputed.apply(lambda row: re.sub(r'[{}\"\"]', '', row['amenities']), axis=1)\n",
    "df_imputed['amenities_new'] = df_imputed.apply(lambda row: row['amenities_new'].lower().split(','), axis=1)\n",
    "df_imputed = df_imputed.reset_index()\n",
    "df_imputed['length_amenities'] = df_imputed.apply(lambda row: len(row['amenities_new']), axis=1)\n",
    "\n",
    "# Create separate columns based on amenities\n",
    "df_imputed['internet'] = df_imputed.apply(lambda row: 'internet' in row.amenities.lower(), axis=1)\n",
    "df_imputed['TV'] = df_imputed.apply(lambda row: 'tv' in row.amenities.lower(), axis=1)\n",
    "df_imputed['air_conditioning'] = df_imputed.apply(lambda row: 'air conditioning' in row.amenities.lower(), axis=1)\n",
    "df_imputed['kitchen'] = df_imputed.apply(lambda row: 'kitchen' in row.amenities.lower(), axis=1)\n",
    "df_imputed['pool'] = df_imputed.apply(lambda row: 'pool' in row.amenities.lower(), axis=1)\n",
    "df_imputed['parking'] = df_imputed.apply(lambda row: 'parking' in row.amenities.lower(), axis=1)\n",
    "\n",
    "# Get information from description based on length in characters\n",
    "df_imputed['description_length'] = df_imputed['description'].apply(len)\n",
    "\n",
    "# Create the target variable superuser\n",
    "df_imputed['superuser'] = False\n",
    "df_imputed.loc[df.review_scores_rating >=96, 'superuser'] = True\n",
    "\n",
    "# Create altnerative target variable grade_grouped\n",
    "new_grades = {\n",
    "    'A':'A',\n",
    "    'B':'<A',\n",
    "    'C':'<A',\n",
    "    'D':'<A',\n",
    "    'F':'<A'\n",
    "}\n",
    "df_imputed['grade_grouped'] = df_imputed['grade'].map(new_grades)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "date_published = datetime.datetime(2018,3,14)\n",
    "df_imputed['host_since'] = pd.to_datetime(df_imputed['host_since'])\n",
    "df_imputed['host_since_days'] = df_imputed.apply(lambda row: (date_published - row['host_since']).days, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removed columns that are not meaningful in a modeling context (i.e., index,id), redundant with newly engineered features (i.e., amenities, description), or are likenly not useful in predicting the target variable grade_grouped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete useless columns\n",
    "df_logistic = df_imputed.drop(['index','id','amenities','description','zipcode','description_length',\n",
    "                               'latitude','longitude','name','neighbourhood','review_scores_rating','thumbnail_url',\n",
    "                               'zipcode'], axis=1)\n",
    "\n",
    "# delete other redundant variables\n",
    "del df_logistic['amenities_new']\n",
    "del df_logistic['host_since']\n",
    "# del df_logistic['grade']\n",
    "del df_logistic['first_review']\n",
    "del df_logistic['last_review']\n",
    "\n",
    "# Remove factor with unncessarily large number of levels\n",
    "df_logistic.drop(['property_type'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-Hot Encode Categorical Variables with multiple levels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_vars = ['room_type','bed_type','cancellation_policy','city']\n",
    "\n",
    "# Create Dummy Variables\n",
    "multiCategorical_vars = ['city','cancellation_policy','bed_type','room_type']\n",
    "\n",
    "dummy_df = pd.get_dummies(df_logistic[multiCategorical_vars], drop_first = True)\n",
    "df_final = pd.concat([df_logistic, dummy_df], axis=1)\n",
    "del df_final['grade']\n",
    "\n",
    "# Delete non-dummy categorical variables\n",
    "for x in categorical_vars:\n",
    "    if x in df_final:\n",
    "        del df_final[x]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Understanding\n",
    "\n",
    "Describe the purpose of the data set you selected (i.e., why was this data collected in the first place?). How will you measure the effective of a good algorithm? Why does your chosen validation method make sense for this specific dataset and the stakeholders needs?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INCOMPLETE**\n",
    "* *This answer was taken from Lab 1 unedited to provided context. It needs to be edited to answer the specific questions asked.*\n",
    "\n",
    "<font color = \"red\">\n",
    "\n",
    "This dataset is provided by Kaggle and aims to predict the price of AirBnb listings in major cities in the United States. Each record is one AirBnB listing from 2018 with 29 attributes that describe the listing and what it offers to guests. A linear regression model would be a strong choice for predicting the continuous value of the listing price. This model could be extremely beneficial for new AirBnb hosts to guide them in setting an initial price for their listings based on location, amenities, and other features that they offered with their listing. Furthermore, the price perdiction model could help ensure that AirBnb guests are not overcharged for their stay and that hosts are adequately compensated for their hospitality. The performance of this model would be measured by the root mean square error (RMSE) to determine how far predictions deviate from actual values. Using the RMSE metric is most appropriate within this context because it heavily penalizes large errors and we want to avoid significant prediction errors in listing prices.  \n",
    "\n",
    "\n",
    "In addition, the rating score from the listing reviews is a potential variable of interest that can predict if a certain listing provided guests with a positive experience during their stay. AirBnB currently employs a \"Superhost\" program that rewards the hosts with the most experience and highest-rated reviews. A model aimed at classifying review rating scores could provide valuable insight into how AirBnB hosts could improve their hospitality standards and provide a better experience for their guests. It could also help new hosts better market their listings and attain superhost status. We would use misclassification rate as our performance evaluation metric with the goal of maximizing the classficiation accuracy for this type of model. A minimal misclassifcation error rate would adequately captures the attributes influencing highly-rated reviews and be useful to further our understanding of what consumers look for when searching for an AirBnb listing to book.\n",
    "\n",
    "* **Recall vs. Precision?** I think we should prioritize recall for the context of this classification model.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling and Evaluation\n",
    "\n",
    "Be as thorough as possible when analyzing the data you have chosen and use visualizations of the results to explain performance and expected outcomes whenever possible. Guide the reader through your analysis with plenty of discussion of the results.\n",
    "\n",
    "**Cluster Analysis**\n",
    "+ Perform cluster analysis using several clustering methods\n",
    "+ How did you determine a suitable number of clusters for each method?\n",
    "+ Use internal and/or external validation measures to describe and compare the clusterings and the clusters (some visual methods would be good.)\n",
    "+ Describe your results. What findings are the most interesting and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "Be critical of your performance and tell the reader how your current model might be usable by other parties. Did you achieve your goals? If not, can you reign in the utility of your modeling?\n",
    "+ How useful is your model for interested parties (i.e., the companies or organizations that might want to use it?)\n",
    "+ How would you deploy your model for interested parties?\n",
    "+ What other data should be collected?\n",
    "+ How often would the model need to be updated, etc.?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exceptional Work\n",
    "\n",
    "You have free reign to provide additional analyses or combine analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
