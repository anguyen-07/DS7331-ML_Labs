{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andy Nguyen, Michael Wolfe, Spencer Fogelman, & Joseph Caguioa\n",
    "\n",
    "DS 7331.407\n",
    "\n",
    "Thursday 6:30pm - 8:00pm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression and SVMs of AirBnB Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instructions\n",
    "[50 Points]\n",
    "* Assess performance of each model using 80/20 training-test split\n",
    "* Adjust model parameters to optimize accuracy\n",
    "    * if dataset size requires stochastic gradient descent, then only linear kernel is appropriate\n",
    "    \n",
    "[10 Points]\n",
    "* Discuss advantages of each model for each classification task\n",
    "* Does one type of model offer superior performance over another in terms of prediction accuracy?\n",
    "    * In terms of training time or efficiency? Explain.\n",
    "\n",
    "[30 points]\n",
    "* Use weights from logistic regression to interpret importance of different features for each classification task. Explain interpretation in detail.\n",
    "    * Why do you think some variables are more important?\n",
    "    \n",
    "[10 points]\n",
    "* Look at the chosen support vectors for the classifcation task. Do these provide any insight into the data? Explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Setup**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#import plotly.graph_objects as go\n",
    "import datetime\n",
    "import csv\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                           int64\n",
       "log_price                  float64\n",
       "property_type               object\n",
       "room_type                   object\n",
       "amenities                   object\n",
       "accommodates                 int64\n",
       "bathrooms                  float64\n",
       "bed_type                    object\n",
       "cancellation_policy         object\n",
       "cleaning_fee                  bool\n",
       "city                        object\n",
       "description                 object\n",
       "first_review                object\n",
       "host_has_profile_pic        object\n",
       "host_identity_verified      object\n",
       "host_response_rate          object\n",
       "host_since                  object\n",
       "instant_bookable            object\n",
       "last_review                 object\n",
       "latitude                   float64\n",
       "longitude                  float64\n",
       "name                        object\n",
       "neighbourhood               object\n",
       "number_of_reviews            int64\n",
       "review_scores_rating       float64\n",
       "thumbnail_url               object\n",
       "zipcode                     object\n",
       "bedrooms                   float64\n",
       "beds                       float64\n",
       "grade                     category\n",
       "dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://raw.githubusercontent.com/anguyen-07/DS7331-ML_Labs/master/data/airbnb_train.csv')\n",
    "df['grade'] = pd.cut(df.review_scores_rating, [0,60,70,80,90,101], right=False, labels = ['F', 'D', 'C', 'B', 'A'])\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to preparing the Airbnb dataset for use with logistic regression and support vector machines is to remove or impute missing data and change the variables to compatible datatypes. Much of the logic behind this work was covered in Lab 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cleanup (from first project)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Clean up datatypes and duplicates\n",
    "df_ratings = df.dropna(subset=['review_scores_rating'])\n",
    "floats = ['log_price','bathrooms','latitude','longitude','review_scores_rating']\n",
    "df_ratings[floats] = df_ratings[floats].astype(np.float64)\n",
    "ints = ['id','accommodates','number_of_reviews','bedrooms','beds']\n",
    "df_ratings[\"host_response_rate\"] = df_ratings[\"host_response_rate\"].str.rstrip('%').astype(np.float64)/100\n",
    "date_time = ['first_review','host_since','last_review']\n",
    "df_ratings[date_time] = df_ratings[date_time].apply(pd.to_datetime)\n",
    "booleans = ['host_has_profile_pic','host_identity_verified','instant_bookable']\n",
    "df_ratings[booleans] = df_ratings[booleans].replace({'t':True,'f':False})\n",
    "df_ratings[booleans] = df_ratings[booleans].astype(np.bool)\n",
    "categorical = ['property_type','room_type','bed_type','cancellation_policy','city','neighbourhood','zipcode']\n",
    "df_ratings[categorical] = df_ratings[categorical].astype('category')\n",
    "df_ratings.drop_duplicates()\n",
    "df_ratings.host_since[df_ratings.host_since.isna()] = df_ratings.first_review[df_ratings.host_since.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Impute missing values\n",
    "df_imputed = df_ratings\n",
    "df_imputed[\"bathrooms\"] = df_imputed[\"bathrooms\"].fillna(df_imputed.groupby([\"property_type\",\"accommodates\"])[\"bathrooms\"].apply(lambda x : x.fillna(x.median())))\n",
    "df_imputed[\"bedrooms\"] = df_imputed[\"bedrooms\"].fillna(df_imputed.groupby([\"property_type\",\"accommodates\"])[\"bedrooms\"].apply(lambda x : x.fillna(x.median())))\n",
    "df_imputed[\"beds\"] = df_imputed[\"beds\"].fillna(df_imputed.groupby([\"property_type\",\"accommodates\"])[\"beds\"].apply(lambda x : x.fillna(x.median())))\n",
    "df_imputed[\"host_response_rate\"] = df_imputed[\"host_response_rate\"].fillna(df_imputed.groupby([\"number_of_reviews\"])[\"host_response_rate\"].apply(lambda x : x.fillna(x.mean())))\n",
    "df_imputed[ints] = df_imputed[ints].astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_imputed['price'] = np.exp(df_imputed['log_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "#Create a new cleaned amenities column where all amenities are in list form\n",
    "df_imputed['amenities_new'] = df_imputed.apply(lambda row: re.sub(r'[{}\"\"]', '', row['amenities']), axis=1)\n",
    "df_imputed['amenities_new'] = df_imputed.apply(lambda row: row['amenities_new'].lower().split(','), axis=1)\n",
    "df_imputed = df_imputed.reset_index()\n",
    "df_imputed['length_amenities'] = df_imputed.apply(lambda row: len(row['amenities_new']), axis=1)\n",
    "\n",
    "# Create separate columns based on amenities\n",
    "df_imputed['internet'] = df_imputed.apply(lambda row: 'internet' in row.amenities.lower(), axis=1)\n",
    "df_imputed['TV'] = df_imputed.apply(lambda row: 'tv' in row.amenities.lower(), axis=1)\n",
    "df_imputed['air_conditioning'] = df_imputed.apply(lambda row: 'air conditioning' in row.amenities.lower(), axis=1)\n",
    "df_imputed['kitchen'] = df_imputed.apply(lambda row: 'kitchen' in row.amenities.lower(), axis=1)\n",
    "df_imputed['pool'] = df_imputed.apply(lambda row: 'pool' in row.amenities.lower(), axis=1)\n",
    "df_imputed['parking'] = df_imputed.apply(lambda row: 'parking' in row.amenities.lower(), axis=1)\n",
    "\n",
    "df_imputed['description_length'] = df_imputed['description'].apply(len)\n",
    "\n",
    "df_imputed['superuser'] = False\n",
    "df_imputed.loc[df.review_scores_rating >=96, 'superuser'] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "date_published = datetime.datetime(2018,3,14)\n",
    "df_imputed['host_since'] = pd.to_datetime(df_imputed['host_since'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "(\"unsupported operand type(s) for -: 'datetime.datetime' and 'str'\", 'occurred at index 0')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-3c8955bc506e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_imputed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'host_since_days'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdate_published\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'host_since'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, axis, broadcast, raw, reduce, result_type, args, **kwds)\u001b[0m\n\u001b[1;32m   6002\u001b[0m                          \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6003\u001b[0m                          kwds=kwds)\n\u001b[0;32m-> 6004\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6005\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6006\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapplymap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mget_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    140\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_raw\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 142\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_standard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    144\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_empty_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;31m# compute the result using the series generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_series_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# wrap results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/pandas/core/apply.py\u001b[0m in \u001b[0;36mapply_series_generator\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseries_gen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                     \u001b[0mresults\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m                     \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-50-3c8955bc506e>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(row)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_imputed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'host_since_days'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdate_published\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'host_since'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: (\"unsupported operand type(s) for -: 'datetime.datetime' and 'str'\", 'occurred at index 0')"
     ]
    }
   ],
   "source": [
    "#df_imputed['host_since_days'] = df.apply(lambda row: (date_published - row['host_since']).days, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 57389 entries, 0 to 57388\n",
      "Data columns (total 42 columns):\n",
      "index                     57389 non-null int64\n",
      "id                        57389 non-null int64\n",
      "log_price                 57389 non-null float64\n",
      "property_type             57389 non-null category\n",
      "room_type                 57389 non-null category\n",
      "amenities                 57389 non-null object\n",
      "accommodates              57389 non-null int64\n",
      "bathrooms                 57389 non-null float64\n",
      "bed_type                  57389 non-null category\n",
      "cancellation_policy       57389 non-null category\n",
      "cleaning_fee              57389 non-null bool\n",
      "city                      57389 non-null category\n",
      "description               57389 non-null object\n",
      "first_review              57388 non-null datetime64[ns]\n",
      "host_has_profile_pic      57389 non-null bool\n",
      "host_identity_verified    57389 non-null bool\n",
      "host_response_rate        57388 non-null float64\n",
      "host_since                57389 non-null datetime64[ns]\n",
      "instant_bookable          57389 non-null bool\n",
      "last_review               57388 non-null datetime64[ns]\n",
      "latitude                  57389 non-null float64\n",
      "longitude                 57389 non-null float64\n",
      "name                      57389 non-null object\n",
      "neighbourhood             52343 non-null category\n",
      "number_of_reviews         57389 non-null int64\n",
      "review_scores_rating      57389 non-null float64\n",
      "thumbnail_url             51592 non-null object\n",
      "zipcode                   56712 non-null category\n",
      "bedrooms                  57389 non-null int64\n",
      "beds                      57389 non-null int64\n",
      "grade                     57389 non-null category\n",
      "price                     57389 non-null float64\n",
      "amenities_new             57389 non-null object\n",
      "length_amenities          57389 non-null int64\n",
      "internet                  57389 non-null bool\n",
      "TV                        57389 non-null bool\n",
      "air_conditioning          57389 non-null bool\n",
      "kitchen                   57389 non-null bool\n",
      "pool                      57389 non-null bool\n",
      "parking                   57389 non-null bool\n",
      "description_length        57389 non-null int64\n",
      "superuser                 57389 non-null bool\n",
      "dtypes: bool(11), category(8), datetime64[ns](3), float64(7), int64(8), object(5)\n",
      "memory usage: 11.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_imputed.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'datetime.datetime' object has no attribute 'dtype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-fe5df4a72e15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdate_published\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'datetime.datetime' object has no attribute 'dtype'"
     ]
    }
   ],
   "source": [
    "date_published.dtype()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Basic model, all numeric data\n",
    "#x_train, x_test, y_train, y_test = train_test_split(df_imputed.loc[:,['log_price','accommodates','bathrooms','number_of_reviews','review_scores_rating','bedrooms','beds']]\n",
    "#                                                    , df_imputed.loc[:,['grade']], test_size=0.2, random_state=0)\n",
    "#LogisticRegression().fit(x_train,y_train).predict(x_test[0].reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Feature Importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>[30 points]\n",
    "* Use weights from logistic regression to interpret importance of different features for each classification task. Explain interpretation in detail.\n",
    "    * Why do you think some variables are more important?</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpretation of Support Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>[10 pts] Look at the chosen support vectors for the classification task. Do these provide any insight into the data? Explain. If you used stochastic gradient descent (and therefore did not explicitly solve for support vectors), try subsampling your data to train the SVC model— then analyze the support vectors from the subsampled dataset.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Comparisons: Advantages, Performance, Efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<i>[10 Points]\n",
    "* Discuss advantages of each model for each classification task\n",
    "* Does one type of model offer superior performance over another in terms of prediction accuracy?\n",
    "    * In terms of training time or efficiency? Explain.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
